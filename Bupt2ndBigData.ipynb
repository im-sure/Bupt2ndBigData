{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import  stats\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.api import qqplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_features = ['loc-id', 'time-stamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loc_time_counts(train_data):\n",
    "    for loc in range(1, 37):\n",
    "        locs = []\n",
    "        loc_time_count = train_data[train_data['loc-id'] == loc]['time-stamp'].value_counts()\n",
    "        locs.extend([loc] * np.shape(loc_time_count)[0])\n",
    "        loc_time_submission = pd.DataFrame({'loc-id': locs, 'time-stamp': loc_time_count.keys(), 'numOfPeople': loc_time_count.values})\n",
    "        loc_time_submission.to_csv('./December/Dec/loc_time_counts%d.csv' %loc, columns = ['loc-id', 'time-stamp', 'numOfPeople'], header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('test1.csv')\n",
    "loc_time_counts(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\陈廷硕\\Anaconda3-4.2.0\\lib\\site-packages\\ipykernel\\__main__.py:12: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "Dec_loc_time_num = pd.read_csv('./December/Dec_loc_time_num.csv')\n",
    "for loc in range(1, 37):\n",
    "    for day in range(1, 31):\n",
    "        for hour in range(0, 24):\n",
    "            day_to_str = str(day)\n",
    "            if day < 10:\n",
    "                day_to_str = '0' + day_to_str\n",
    "            hour_to_str = str(hour)\n",
    "            if hour < 10:\n",
    "                hour_to_str = '0' + hour_to_str\n",
    "            time = int('11' + day_to_str + hour_to_str)\n",
    "            if Dec_loc_time_num[Dec_loc_time_num['loc-id'] == loc][Dec_loc_time_num['time-stamp'] == time].empty:\n",
    "                Dec_loc_time_num = Dec_loc_time_num.append(pd.Series({'loc-id': loc, 'time-stamp': time, 'numOfPeople': np.NaN}), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Dec_loc_time_num['loc-id'] = Dec_loc_time_num['loc-id'].astype(int)\n",
    "Dec_loc_time_num['time-stamp'] = Dec_loc_time_num['time-stamp'].astype(int)\n",
    "Dec_loc_time_num = Dec_loc_time_num.sort_values(by = selected_features)\n",
    "Dec_loc_time_num.to_csv('./December/Dec_loc_time_num_fillna.csv', columns = ['loc-id', 'time-stamp', 'numOfPeople'], index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc_time_num = pd.read_csv('loc_time_num_fillna_diff.csv')\n",
    "loc_time_num = loc_time_num.append(Dec_loc_time_num)\n",
    "loc_time_num = loc_time_num.sort_values(by = selected_features)\n",
    "loc_time_num.to_csv('./December/all_loc_time_num_fillna_diff.csv', columns = ['loc-id', 'time-stamp', 'numOfPeople'], index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#生成与星期有关数据的训练集\n",
    "#locs: 预测地点，默认为全部\n",
    "#endDate: 产生训练集截止日期后一天，默认为2015.11.1\n",
    "def generateData(all_train_data, locs = range(1, 37), endDate = '12/1/2015'):\n",
    "    t = pd.date_range('7/1/2015', endDate, freq='h')\n",
    "    t = t[:-1]\n",
    "    week_data = pd.DataFrame()\n",
    "    for loc in range(1, 37):\n",
    "        dt = all_train_data[all_train_data['loc-id'] == loc]['numOfPeople']\n",
    "        dt = dt[:len(t)]\n",
    "        dt.index = pd.Index(t)\n",
    "#         for month in range(7, 11):\n",
    "        for month in range(7, 12):\n",
    "            for weekday in range(7):\n",
    "                for hour in range(24):\n",
    "                    nums = []\n",
    "                    for time in t:\n",
    "                        if time.month == month and time.weekday() == weekday and time.hour == hour:\n",
    "                            if not pd.isnull(dt[time]):\n",
    "                                nums.append(dt[time])\n",
    "                            else:\n",
    "                                nums.append(np.NaN)\n",
    "                    week_data = week_data.append(pd.Series({'loc-id': loc, 'month': month, 'weekday': weekday, 'hour': hour, 'numOfPeople': nums}), ignore_index = True)\n",
    "    week_data['loc-id'] = week_data['loc-id'].astype(int)\n",
    "    week_data['month'] = week_data['month'].astype(int)\n",
    "    week_data['weekday'] = week_data['weekday'].astype(int)\n",
    "    week_data['hour'] = week_data['hour'].astype(int)\n",
    "    week_data.sort_values(by = ['loc-id', 'month', 'weekday', 'hour'])\n",
    "    return week_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>loc-id</th>\n",
       "      <th>month</th>\n",
       "      <th>numOfPeople</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>[7.0, 4.0, 5.0, nan]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>[2.0, 1.0, 3.0, nan]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>[3.0, 1.0, 1.0, nan]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>[2.0, 1.0, 1.0, nan]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>[3.0, 3.0, 1.0, nan]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hour  loc-id  month           numOfPeople  weekday\n",
       "0     0       1      7  [7.0, 4.0, 5.0, nan]        0\n",
       "1     1       1      7  [2.0, 1.0, 3.0, nan]        0\n",
       "2     2       1      7  [3.0, 1.0, 1.0, nan]        0\n",
       "3     3       1      7  [2.0, 1.0, 1.0, nan]        0\n",
       "4     4       1      7  [3.0, 3.0, 1.0, nan]        0"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data = pd.read_csv('./December/all_loc_time_num_fillna_all_diff_four.csv')\n",
    "data = generateData(all_train_data, endDate = '12/1/2015')\n",
    "# all_train_data = pd.read_csv('loc_time_num_fillna_diff.csv')\n",
    "# data = generateData(all_train_data, endDate = '11/1/2015')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#时间序列预测\n",
    "def doArma(trainData, p, q):\n",
    "    t = pd.date_range('11/1/2015', periods = len(trainData) + 1, freq='h')\n",
    "    tTrain = t[:-1]\n",
    "    tPredict = t[-1:]\n",
    "    dt = pd.Series(trainData)\n",
    "    dt.index = pd.Index(tTrain)\n",
    "    dt = dt.astype(float)\n",
    "    arma_mod = sm.tsa.ARMA(dt, (p, q)).fit()\n",
    "    prediction = arma_mod.predict(str(tPredict.values[0]), str(tPredict.values[0]), dynamic=True)\n",
    "    return prediction.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#加权均值预测\n",
    "#trainData: generateData产生的训练集\n",
    "#startDate: 预测起始日期\n",
    "#endDate: 预测截止日期后一天\n",
    "#locs: 预测地点，默认为全部\n",
    "#delta: 九十月权值 or 非节日权重\n",
    "#doArmaOrNot: 是否做时间序列预测\n",
    "def meanPredict(trainData, startDate, endDate, locs = range(1, 37), delta = 0.8, doArmaOrNot = False):\n",
    "# def meanPredict(trainData, startDate, endDate, locs = range(1, 37), doArmaOrNot = False):\n",
    "#     delta = [0.65, 1.02, 1.19, 0.78, 0.94, 1.16, 0.78, 1.05, 1.11, 0.73,\\\n",
    "#             0.76, 1.14, 0.69, 0.71, 1.0, 1.19, 1.19, 0.6, 0.76, 0.71,\\\n",
    "#             1.0, 1.05, 1.17, 0.6, 0.78, 0.71, 1.17, 0.97, 0.83, 0.79,\\\n",
    "#             0.72, 1.15, 0.6, 0.87, 1.11, 0.82]\n",
    "    t = pd.date_range(startDate, endDate, freq='h')\n",
    "    t = t[:-1]\n",
    "    prediction = pd.DataFrame()\n",
    "    for loc in locs:\n",
    "        count = 0\n",
    "        numsInAWeek = []\n",
    "        \n",
    "        #Arma预测\n",
    "        armaTrainData = []\n",
    "#         armaPredictData = []\n",
    "        \n",
    "        for time in t:\n",
    "            data = trainData[trainData['loc-id'] == loc][trainData['weekday'] == time.weekday()]\\\n",
    "            [trainData['hour'] == time.hour][['month', 'numOfPeople']]\n",
    "#             numsJulToAug = []\n",
    "#             numsSepToOct = []\n",
    "            numsOfSep = []\n",
    "            numsOfOct = []\n",
    "#             holiday = []\n",
    "#             for month in range(9, 11):\n",
    "            for month in range(10, 12):\n",
    "                nums = data[data['month'] == month]['numOfPeople'].values[0]\n",
    "                leng = len(nums)\n",
    "                for day in range(leng):\n",
    "                    if not pd.isnull(nums[day]):\n",
    "                        if month == 10 and day == 0:\n",
    "                            numsOfSep.append(nums[day])\n",
    "                        elif leng >= 3 and (nums[day] > np.sum(nums) * 0.35 or nums[day] < np.sum(nums) * 0.05):\n",
    "                            numsOfSep.append(nums[day])\n",
    "#                             print(loc, time, nums[day])\n",
    "                        else:\n",
    "                            numsOfOct.append(nums[day])\n",
    "                        \n",
    "#                         if month == 10 and day == 0:\n",
    "#                             holiday.append(nums[day])\n",
    "#                         else:\n",
    "#                             numsSepToOct.append(nums[day])\n",
    "\n",
    "#                         if month < 9:\n",
    "#                             numsJulToAug.append(nums[day])\n",
    "#                         else:\n",
    "#                             numsSepToOct.append(nums[day])\n",
    "            if count == 168:\n",
    "#                 numsSepToOct.append(numsInAWeek[0])\n",
    "                numsOfOct.append(numsInAWeek[0])\n",
    "                numsInAWeek = numsInAWeek[1:]\n",
    "            else:\n",
    "                count += 1\n",
    "#             lenJulToAug = len(numsJulToAug)\n",
    "#             if lenJulToAug == 0:\n",
    "#                 lenJulToAug = 1\n",
    "            \n",
    "            if doArmaOrNot:\n",
    "                try:\n",
    "    #                 armaPredictData.append(doArma(armaTrainData, 1, 0))\n",
    "                    armaPredictData = doArma(armaTrainData, 1, 0)\n",
    "#                     numsSepToOct.append(armaPredictData)\n",
    "                    numsOfOct.append(armaPredictData)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "#             lenHoliday = len(holiday)\n",
    "#             if lenHoliday == 0:\n",
    "#                 lenHoliday = 1\n",
    "#             lenSepToOct = len(numsSepToOct)\n",
    "#             if lenSepToOct == 0:\n",
    "#                 lenSepToOct = 1\n",
    "\n",
    "            lenSep = len(numsOfSep)\n",
    "            if lenSep == 0:\n",
    "                lenSep = 1\n",
    "            lenOct = len(numsOfOct)\n",
    "            if lenOct == 0:\n",
    "                lenOct = 1\n",
    "             \n",
    "            #根据权重计算人数\n",
    "            numOfPeople = np.sum(numsOfSep) / lenSep * (1 - delta) + np.sum(numsOfOct) / lenOct * delta\n",
    "#             numOfPeople = np.sum(numsOfSep) / lenSep * (1 - delta[loc - 1]) + np.sum(numsOfOct) / lenOct * delta[loc - 1]\n",
    "#             numOfPeople = np.sum(holiday) / lenHoliday * (1 - delta) + np.sum(numsSepToOct) / lenSepToOct * delta\n",
    "#             numOfPeople = np.sum(holiday) / lenHoliday * (1 - delta[loc - 1]) + np.sum(numsSepToOct) / lenSepToOct * delta[loc - 1]\n",
    "            \n",
    "            if doArmaOrNot:\n",
    "                armaTrainData.append(numOfPeople)\n",
    "    \n",
    "            numsInAWeek.append(numOfPeople)\n",
    "            day_to_str = str(time.day)\n",
    "            if time.day < 10:\n",
    "                day_to_str = '0' + day_to_str\n",
    "            hour_to_str = str(time.hour)\n",
    "            if time.hour < 10:\n",
    "                hour_to_str = '0' + hour_to_str\n",
    "            prediction = prediction.append(pd.Series({'loc-id': loc, 'time-stamp': str(time.month) + day_to_str + hour_to_str, 'numOfPeople': numOfPeople}), ignore_index = True)\n",
    "        \n",
    "#         print('plot')\n",
    "#         t = pd.date_range('11/1/2015', periods = len(armaTrainData), freq='h')\n",
    "#         armaTrainData = pd.Series(armaTrainData)\n",
    "#         armaTrainData.index = pd.Index(t)\n",
    "#         t = pd.date_range('11/1/2015', periods = len(armaPredictData), freq='h')\n",
    "#         armaPredictData = pd.Series(armaPredictData)\n",
    "#         armaPredictData.index = pd.Index(t)\n",
    "#         plt.rc('figure', figsize=(12, 8))\n",
    "#         plt.plot(armaTrainData)\n",
    "#         plt.plot(armaPredictData, 'r')\n",
    "#         plt.show()\n",
    "        \n",
    "    prediction['loc-id'] = prediction['loc-id'].astype(int)\n",
    "    prediction['time-stamp'] = prediction['time-stamp'].astype(int)\n",
    "    prediction['numOfPeople'] = prediction['numOfPeople'].astype(int)\n",
    "    prediction.sort_values(by = ['loc-id', 'time-stamp'])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\陈廷硕\\Anaconda3-4.2.0\\lib\\site-packages\\ipykernel\\__main__.py:26: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc-id</th>\n",
       "      <th>numOfPeople</th>\n",
       "      <th>time-stamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>120100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>120102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>120103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loc-id  numOfPeople  time-stamp\n",
       "0       1            9      120100\n",
       "1       1            4      120101\n",
       "2       1            3      120102\n",
       "3       1            3      120103\n",
       "4       1            2      120104"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_prediction = meanPredict(data, '12/1/2015', '1/1/2016', delta = 0.9)\n",
    "# # mean_prediction = meanPredict(data, '12/1/2015', '1/1/2016')\n",
    "# mean_prediction = meanPredict(data, '11/1/2015', '12/1/2015', delta = 0.76)\n",
    "mean_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_prediction.to_csv('./December/result/result.csv', columns = ['loc-id', 'time-stamp', 'numOfPeople'], header = False, index = False)\n",
    "# mean_prediction.to_csv('./result/result.csv', columns = ['loc-id', 'time-stamp', 'numOfPeople'], header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "\n",
    "# sol_file: 提交的答案\n",
    "# ans_file: 正确的答案\n",
    "def count_score(sol_file, ans_file):\n",
    "    sol_map = dict()\n",
    "    with open(sol_file) as fp:\n",
    "        lines = fp.readlines()\n",
    "        for line in lines:\n",
    "            nums = line[:-1].split(',')\n",
    "            key = int(nums[0]) * 1000000 + int(nums[1])\n",
    "            val = float(nums[2])\n",
    "            sol_map[key] = val\n",
    "\n",
    "    ans_map = dict()\n",
    "    with open(ans_file) as fp:\n",
    "        lines = fp.readlines()\n",
    "        for line in lines:\n",
    "            nums = line[:-1].split(',')\n",
    "            key = int(nums[0]) * 1000000 + int(nums[1])\n",
    "            val = float(nums[2])\n",
    "            ans_map[key] = val\n",
    "\n",
    "    square_count = 0.0\n",
    "    for key, ans in ans_map.items():\n",
    "        sol = sol_map[key]\n",
    "        square_count += pow(ans - sol, 2)\n",
    "\n",
    "    if len(ans_map) == 0:\n",
    "        return 0\n",
    "    return sqrt(square_count / len(ans_map))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.027009203567388"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_score('./December/result/result_63.3.csv', './December/result/result_61.6.csv')\n",
    "# count_score('./result/result.csv', './December/Dec_loc_time_num.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Dec_train_data = pd.read_csv('./December/Dec_loc_time_num.csv')\n",
    "for loc in range(1, 37):\n",
    "    loc_data = Dec_train_data[Dec_train_data['loc-id'] == loc]\n",
    "    loc_data.to_csv('./December/locs/%d.csv' %loc, columns = ['loc-id', 'time-stamp', 'numOfPeople'], header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\陈廷硕\\Anaconda3-4.2.0\\lib\\site-packages\\ipykernel\\__main__.py:29: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 65.92370957304335\n",
      "2 1.02 35.59231587913728\n",
      "3 1.19 95.124681528882\n",
      "4 0.78 50.866039327183046\n",
      "5 0.94 34.610099578096495\n",
      "6 1.16 70.65619161682226\n",
      "7 0.78 87.1970975030112\n",
      "8 1.05 144.09838937797204\n",
      "9 1.11 49.71448654480697\n",
      "10 0.73 35.16069993819641\n",
      "11 0.6 0\n",
      "12 1.14 79.99861509592643\n",
      "13 0.69 31.233859140915207\n",
      "14 0.71 36.944376520950236\n",
      "15 1.0 37.15288266941722\n",
      "16 1.19 75.6714595086725\n",
      "17 1.19 55.41043716451432\n",
      "18 0.6 31.341253408281375\n",
      "19 0.76 108.91194461046096\n",
      "20 0.71 57.838276141758925\n",
      "21 1.0 51.53509665315822\n",
      "22 1.05 40.44449078097503\n",
      "23 1.17 31.96445867999388\n",
      "24 0.6 42.17847169088046\n",
      "25 0.78 21.221195311169033\n",
      "26 0.71 58.7203239352247\n",
      "27 1.17 80.8172427402589\n",
      "28 0.97 16.951871986757737\n",
      "29 0.83 131.89759381706216\n",
      "30 0.79 33.849831017419184\n",
      "31 0.72 143.47302943208038\n",
      "32 1.15 82.22369264502724\n",
      "33 0.6 44.97557140405653\n",
      "34 0.87 91.23655710578949\n",
      "35 1.11 66.43365740146233\n",
      "36 0.82 41.532116087031575\n"
     ]
    }
   ],
   "source": [
    "Dec_train_data = pd.read_csv('loc_time_num_fillna_diff.csv')\n",
    "for loc in range(1, 37):\n",
    "    print(loc, end = ' ')\n",
    "    loc_train_data = generateData(Dec_train_data, locs = range(loc, loc + 1), endDate = '11/1/2015')\n",
    "    m = 1000000\n",
    "    d = 0;\n",
    "    for weight in range(60, 120):\n",
    "        dlt = weight / 100\n",
    "        predict_loc_data = meanPredict(loc_train_data, '11/1/2015', '12/1/2015', locs = range(loc, loc + 1), delta = dlt)\n",
    "        predict_loc_data.to_csv('./December/delta/%d.csv' %loc, columns = ['loc-id', 'time-stamp', 'numOfPeople'], header = False, index = False)\n",
    "        score = count_score('./December/delta/%d.csv' %loc, './December/locs/%d.csv' %loc)\n",
    "        if score < m:\n",
    "            m = score\n",
    "            d = dlt\n",
    "    print(d, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\陈廷硕\\Anaconda3-4.2.0\\lib\\site-packages\\ipykernel\\__main__.py:26: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "E:\\陈廷硕\\Anaconda3-4.2.0\\lib\\site-packages\\statsmodels\\base\\data.py:503: FutureWarning: TimeSeries is deprecated. Please use Series\n",
      "  return TimeSeries(result, index=self.predict_dates)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 202.6923351191391 237.04659124263543\n",
      "2 62.553917483980115 110.35375216676572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\陈廷硕\\Anaconda3-4.2.0\\lib\\site-packages\\statsmodels\\base\\model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 87.8890855455027 175.6020332287587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\陈廷硕\\Anaconda3-4.2.0\\lib\\site-packages\\statsmodels\\base\\model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 121.30984713676659 182.07270966550223\n",
      "5 68.78594458782626 97.81795891562936\n",
      "6 134.8840772134142 207.07110698925067\n",
      "7 208.0985818142123 309.88719970855504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\陈廷硕\\Anaconda3-4.2.0\\lib\\site-packages\\statsmodels\\base\\model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 199.94001569606624 288.0875852759425\n",
      "9 60.347454552250674 105.45832412891274\n",
      "10 86.38728472965776 123.29455846933452\n",
      "11 66.13674444298904 97.44710324598923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\陈廷硕\\Anaconda3-4.2.0\\lib\\site-packages\\statsmodels\\base\\model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 90.07315271214932 164.30498591053689\n",
      "13 74.66696428512114 123.38614484917154\n",
      "14 93.49488663643854 138.86820290396855\n",
      "15 71.22121684157791 106.62384557145012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\陈廷硕\\Anaconda3-4.2.0\\lib\\site-packages\\statsmodels\\base\\model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 96.15675216881195 162.48576005983483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\陈廷硕\\Anaconda3-4.2.0\\lib\\site-packages\\statsmodels\\base\\model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 31.895972887180495 53.92333377978336\n",
      "18 65.55333304786424 92.51240315137265\n",
      "19 311.7520113534387 396.0681251994346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\陈廷硕\\Anaconda3-4.2.0\\lib\\site-packages\\statsmodels\\base\\model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 165.65858091900571 209.60208037795195\n",
      "21 148.65704170802914 196.17636308204607\n",
      "22 102.32339196493574 145.24532673470634\n",
      "23 51.16921817742468 83.90177973067858\n",
      "24 53.8883585023039 81.55615343102558\n",
      "25 39.5558676641869 60.830832013517536\n",
      "26 138.98730544326762 191.016275827098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\陈廷硕\\Anaconda3-4.2.0\\lib\\site-packages\\statsmodels\\base\\model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 80.90487329059658 127.29997349265838\n",
      "28 32.24648919764399 43.082174625845006\n",
      "29 394.082820148002 430.230796516945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\陈廷硕\\Anaconda3-4.2.0\\lib\\site-packages\\statsmodels\\base\\model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 77.94961990441803 88.31004962553733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\陈廷硕\\Anaconda3-4.2.0\\lib\\site-packages\\statsmodels\\base\\model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 493.98595721530984 656.8505908998119\n",
      "32 108.52079776152601 170.76566924620255\n",
      "33 167.8228379884426 189.41228148205602\n",
      "34 278.7610508245191 366.8522022171939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\陈廷硕\\Anaconda3-4.2.0\\lib\\site-packages\\statsmodels\\base\\model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 112.64890282928626 135.63589604635013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\陈廷硕\\Anaconda3-4.2.0\\lib\\site-packages\\statsmodels\\base\\model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 84.70962001557669 110.57373183993738\n"
     ]
    }
   ],
   "source": [
    "for loc in range(1, 37):\n",
    "    Dec_arma_train_data = generateData(locs = range(loc, loc + 1), endDate = '10/15/2015')\n",
    "    do_arma = meanPredict(Dec_arma_train_data, '10/15/2015', '11/1/2015', locs = range(loc, loc + 1), delta = 0.8, doArmaOrNot = True)\n",
    "    do_arma.to_csv('./doarma/%d.csv' %loc, columns = ['loc-id', 'time-stamp', 'numOfPeople'], header = False, index = False)\n",
    "    not_do_arma = meanPredict(Dec_arma_train_data, '10/15/2015', '11/1/2015', locs = range(loc, loc + 1), delta = 0.8, doArmaOrNot = False)\n",
    "    not_do_arma.to_csv('./notdoarma/%d.csv' %loc, columns = ['loc-id', 'time-stamp', 'numOfPeople'], header = False, index = False)\n",
    "    do_arma_score = count_score('./doarma/%d.csv' %loc, './locs/%d.csv' %loc)\n",
    "    not_do_arma_score = count_score('./notdoarma/%d.csv' %loc, './locs/%d.csv' %loc)\n",
    "    print(loc, do_arma_score, not_do_arma_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
